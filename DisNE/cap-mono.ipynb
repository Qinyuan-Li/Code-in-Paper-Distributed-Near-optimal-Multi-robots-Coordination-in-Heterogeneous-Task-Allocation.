{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "from functools import reduce # python3 compatibility\n",
    "from operator import mul\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for generating environment with capability\n",
    "# generating task\n",
    "def gen_tasks(task_num, max_capNum, capabilities): # n is the number of task, max_capNum is the maximum number of cap a task could require\n",
    "    return [sorted(np.random.choice(capabilities, np.random.randint(1, max_capNum+1),replace=False)) for j in range(0, task_num)]\n",
    "\n",
    "\n",
    "def gen_constraints(agent_num, task_num, power=1, a_min_edge=2,\n",
    "                    t_max_edge=5):  # power is the inforce you put in the probabilities\n",
    "\n",
    "    # the maximum tasks an agent could work on depends on the number of tasks available (e.g, if |T| = 1/2|A|, the roughly each agent can work on two tasks)\n",
    "    # calculate the max and min edges for agents\n",
    "    seats = math.floor(t_max_edge * task_num)\n",
    "    a_taskInds = [[] for i in range(0, agent_num)]\n",
    "    t_counter = [0 for j in range(0, task_num)]  # each indicate the current number of agents on the task\n",
    "\n",
    "    ## generating the number of tasks the agents could work on.\n",
    "    a_taskNums = []\n",
    "    for i in range(0, agent_num):\n",
    "        a_max_edge = min((seats - (agent_num - 1 - i) * a_min_edge), t_max_edge)\n",
    "        a_min_edge = min(a_min_edge, a_max_edge)\n",
    "        a_taskNums.append(\n",
    "            np.random.randint(a_min_edge, a_max_edge + 1))  # indicate the number of task the agent could work on\n",
    "        seats -= a_taskNums[i]\n",
    "\n",
    "    t_indexes = [j for j in range(0, task_num) if\n",
    "                 t_counter[j] < t_max_edge]  # make sure no further draw for those reached the maximum limit.\n",
    "    for i in range(0, agent_num):\n",
    "        if any([tc == 0 for tc in t_counter]):\n",
    "            t_prob = [(math.e ** (t_max_edge - t_counter[j])) ** power for j in\n",
    "                      t_indexes]  # power is used to manify the probability\n",
    "            sum_prob = sum(t_prob)\n",
    "            t_prop_2 = [prop / sum_prob for prop in t_prob]\n",
    "\n",
    "            # draw tasks accounting to their current allocations\n",
    "            a_taskInds[i] = list(np.random.choice(t_indexes, min(a_taskNums[i], len(t_indexes)), replace=False,\n",
    "                                                  p=[prop / sum_prob for prop in t_prob]))\n",
    "            # increase the chosen task counters\n",
    "        else:\n",
    "            a_taskInds[i] = list(np.random.choice(t_indexes, min(a_taskNums[i], len(t_indexes)), replace=False))\n",
    "\n",
    "        for j in a_taskInds[i]:\n",
    "            t_counter[j] += 1\n",
    "        t_indexes = [j for j in range(0, task_num) if\n",
    "                     t_counter[j] < t_max_edge]  # make sure no further draw for those reached the maximum limit.\n",
    "\n",
    "    # get also the list of agents for each task\n",
    "    t_agents = [[i for i in range(0, agent_num) if j in a_taskInds[i]] for j in range(0, task_num)]\n",
    "\n",
    "    return a_taskInds, t_agents\n",
    "\n",
    "\n",
    "def gen_agents(constraints, tasks, max_capNum, capabilities,\n",
    "               max_capVal):  # m is the number of task, max_capNum is the maximum number of cap a task could require, max_capVal is the maximum capability value\n",
    "\n",
    "    a_taskInds = constraints[0]\n",
    "    agent_num = len(a_taskInds)\n",
    "    caps_lists = []\n",
    "    contri_lists = []\n",
    "    for i in range(0, agent_num):\n",
    "        t_caps = [tasks[j] for j in a_taskInds[i]]  # lists of caps that each task agent could perform\n",
    "\n",
    "        caps_union = set(itertools.chain(*t_caps))  # union of caps of tasks that agent could perform\n",
    "        a_cap_num = np.random.randint(min(3, max_capNum, len(caps_union)),\n",
    "                                      min(len(caps_union), max_capNum) + 1)  # the num of caps the agent will have\n",
    "\n",
    "        a_caps = set([np.random.choice(t_c) for t_c in\n",
    "                      t_caps])  # initial draw to guarantee the agent has some contribution to each of the task that he could do\n",
    "\n",
    "        rest_choices = list(caps_union.difference(a_caps))\n",
    "        if rest_choices != []:\n",
    "            # if min(len(rest_choices), a_cap_num - len(a_taskInds[i])) < 0:\n",
    "            #     print(\"negative number a_cap_num - len(a_taskInds[i]): {}!\".format(a_cap_num - len(a_taskInds[i])))\n",
    "            # else:\n",
    "            update_len = max(0, a_cap_num - len(a_taskInds[i]))\n",
    "            a_caps.update(np.random.choice(rest_choices, min(len(rest_choices), update_len), replace=False))\n",
    "\n",
    "        caps_lists.append(sorted(list(a_caps)))\n",
    "\n",
    "        contri_lists.append(\n",
    "            [(np.random.randint(1, max_capVal + 1) if c in caps_lists[i] else 0) for c in range(0, len(capabilities))])\n",
    "    return caps_lists, contri_lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(agents, tasks, constraints, gamma = 1):\n",
    "    task_num = len(tasks)\n",
    "    agent_num = len(agents)\n",
    "    a_taskInds = constraints[0]\n",
    "    alloc = [np.random.choice(a_taskInds[i]+[task_num]) for i in range(0,agent_num)]\n",
    "    return alloc, sys_reward_agents(agents,tasks, alloc, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_reward(task, agents, gamma=1):  # task is represented by a list of capabilities it requires, agents is\n",
    "    # a list of agents, where each represented by a list cap contribution values\n",
    "    if agents == []:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum([max([agent[cap] for agent in agents]) for cap in task]) * (gamma ** len(agents))\n",
    "\n",
    "\n",
    "def sys_reward_agents(agents, tasks, alloc, gamma=1): #alloc is a vector of size M each element indicate which task the agent is alloated to\n",
    "    return sum([task_reward(tasks[j], [agents[i] for i in range(0,len(agents)) if alloc[i] == j], gamma) for j in range(0, len(tasks))])\n",
    "\n",
    "\n",
    "def resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma=1):\n",
    "    a_taskInds = constraints[0]\n",
    "    agent_num = len(agents)\n",
    "    task_num = len(tasks)\n",
    "    a_msg_sum = [{d_key: sum([r_msgs[j][i][0] for j in a_taskInds[i] if j != d_key])\n",
    "                         + r_msgs[d_key][i][1] for d_key in a_taskInds[i]}\n",
    "                 for i in range(0, agent_num)]\n",
    "    alloc = [max(ams, key=ams.get) if ams != {} else task_num for ams in a_msg_sum]\n",
    "    return alloc, sys_reward_agents(agents, tasks, alloc, gamma), iteration, iter_over, converge\n",
    "\n",
    "\n",
    "# Agent contribution\n",
    "def agent_con(competency_lists, t_caps_lists, query_agentIndex, query_taskIndex, member, a_taskInds):\n",
    "    # the marginal contribution of an agent to a coalition\n",
    "    if query_taskIndex == len(t_caps_lists):\n",
    "        return 0\n",
    "    if query_taskIndex not in a_taskInds[query_agentIndex]:\n",
    "        return 0\n",
    "    curr_pro = [competency_lists[mem] for mem in member]\n",
    "    cur_reward = task_reward(t_caps_lists[query_taskIndex], curr_pro, gamma=1)\n",
    "    if query_agentIndex in member:\n",
    "        remained_mems = member[:]\n",
    "        remained_mems.remove(query_agentIndex)  # the remained coalition members besides of agent i\n",
    "        coal_pro = [competency_lists[mem] for mem in remained_mems]\n",
    "        new_reward = task_reward(t_caps_lists[query_taskIndex], coal_pro, gamma=1)\n",
    "        return cur_reward - new_reward\n",
    "    else:\n",
    "        added_mems = member[:]\n",
    "        added_mems.append(query_agentIndex)\n",
    "        coal_pro = [competency_lists[mem] for mem in added_mems]\n",
    "        new_reward = task_reward(t_caps_lists[query_taskIndex], coal_pro, gamma=1)\n",
    "        return new_reward - cur_reward\n",
    "\n",
    "\n",
    "def aim_tasks(movement_values, a_tasks, a_index):\n",
    "    max_mv = max(movement_values['agent ' + str(a_index)])\n",
    "    target_tasks = []  # aiming tasks are the tasks the agent makes proposal to\n",
    "    max_num = movement_values['agent ' + str(a_index)].count(max_mv)\n",
    "    first_pos = 0\n",
    "    for ind in range(max_num):\n",
    "        new_list = movement_values['agent ' + str(a_index)][first_pos:]\n",
    "        index_add_t = first_pos + new_list.index(max_mv)\n",
    "        act_task = a_tasks[a_index][index_add_t]\n",
    "        target_tasks.append(act_task)\n",
    "        next_pos = new_list.index(max_mv) + 1\n",
    "        first_pos += next_pos\n",
    "    return target_tasks\n",
    "\n",
    "\n",
    "def accepted_tasks(instruction_received, propose_states, a_index):\n",
    "    accept_num = instruction_received['agent ' + str(a_index)].count(1)\n",
    "    accept_tasks = []  # the index of accept message, which corresponding to the index of sending tasks\n",
    "    first_pos = 0\n",
    "    for ind in range(accept_num):\n",
    "        new_list = instruction_received['agent ' + str(a_index)][first_pos:]\n",
    "        new_t_ind = first_pos + new_list.index(1)\n",
    "        act_task = propose_states['agent ' + str(a_index)][new_t_ind]\n",
    "        accept_tasks.append(act_task)\n",
    "        next_pos = new_list.index(1) + 1\n",
    "        first_pos += next_pos\n",
    "    return accept_tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OPD(agents, tasks, constraints, gamma):\n",
    "    task_num = len(tasks)\n",
    "    agent_num = len(agents)\n",
    "    a_taskInds = [list(con) for con in constraints[0]]\n",
    "    t_agentInds = [list(con) for con in constraints[1]]\n",
    "\n",
    "    a_ubs = [[0 for j in a_taskInds[i]] for i in range(0, agent_num)]\n",
    "    a_lbs = [[0 for j in a_taskInds[i]] for i in range(0, agent_num)]\n",
    "\n",
    "    for j in range(0, task_num):\n",
    "\n",
    "        linked_agentInds = t_agentInds[j]\n",
    "        com_dict = []\n",
    "        com_rewards = []\n",
    "        for c in itertools.product(*[[0, 1] for i in linked_agentInds]):\n",
    "            com_dict.append({linked_agentInds[i]: c[i] for i in range(0, len(c))})\n",
    "            com_rewards.append(\n",
    "                task_reward(tasks[j], [agents[a_key] for a_key in com_dict[-1].keys() if com_dict[-1][a_key] == 1],\n",
    "                            gamma)\n",
    "            )\n",
    "\n",
    "        for i in t_agentInds[j]:\n",
    "            t_ind = a_taskInds[i].index(j)\n",
    "            cons_j = [com_rewards[c]\n",
    "                      for c in range(0, len(com_dict)) if com_dict[c][i] == 1]\n",
    "\n",
    "            a_lbs[i][t_ind] = min(cons_j)\n",
    "            a_ubs[i][t_ind] = max(cons_j)\n",
    "\n",
    "    for i in range(0, agent_num):\n",
    "        t_flag = [True for j in a_taskInds[i]]\n",
    "        for t_ind in range(0, len(a_taskInds[i])):\n",
    "            for t2_ind in range(0, len(a_taskInds[i])):\n",
    "                if t_ind != t2_ind and a_ubs[i][t_ind] < a_lbs[i][t2_ind]:\n",
    "                    t_flag[t_ind] = False\n",
    "                    break\n",
    "\n",
    "        for t_ind in range(0, len(t_flag)):\n",
    "            if not t_flag[t_ind]:\n",
    "                t_agentInds[a_taskInds[i][t_ind]].remove(i)\n",
    "\n",
    "        new_a_taskInds = [a_taskInds[i][t_ind]\n",
    "                          for t_ind in range(0, len(a_taskInds[i])) if t_flag[t_ind]]\n",
    "        a_taskInds[i] = new_a_taskInds\n",
    "\n",
    "    return a_taskInds, t_agentInds\n",
    "\n",
    "\n",
    "def FMS(agents, tasks, constraints, gamma, time_bound):\n",
    "    converge = False\n",
    "    iter_over = False\n",
    "    record_u = []\n",
    "    record_t = []\n",
    "    start_time = time.time()\n",
    "    a_taskInds = constraints[0]\n",
    "    t_agentInds = constraints[1]\n",
    "    task_num = len(tasks)\n",
    "    agent_num = len(agents)\n",
    "\n",
    "    q_msgs = [{t_key: {} for t_key in a_taskInds[i]} for i in range(0, agent_num)]\n",
    "    r_msgs = [\n",
    "        {t_agentInds[j][i]: ({1: -100} if len(a_taskInds[t_agentInds[j][i]]) == 1 else {key: -100 for key in [0, 1]})\n",
    "         for i in range(0, len(t_agentInds[j]))}\n",
    "        for j in range(0, task_num)]\n",
    "\n",
    "    q_flags = [False for i in range(0, agent_num)]\n",
    "    r_flags = [False for j in range(0, task_num)]\n",
    "\n",
    "    iteration = 0\n",
    "    while iteration < agent_num + task_num:  # True:\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            r = resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)\n",
    "        iteration += 1\n",
    "\n",
    "        if iteration > agent_num + task_num:\n",
    "            iter_over = True\n",
    "            r = resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)\n",
    "\n",
    "        if all(q_flags) and all(r_flags):  # converge, msgs are all the same.\n",
    "            converge = True\n",
    "            # break\n",
    "        for i in range(0, agent_num):\n",
    "            linked_taskInds = a_taskInds[i]\n",
    "\n",
    "            flag = True\n",
    "            for t_key in linked_taskInds:\n",
    "\n",
    "                ####### check time bound\n",
    "                if time.time() - start_time >= time_bound:\n",
    "                    r = resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)\n",
    "                ####### check time bound\n",
    "                msgs = {}\n",
    "\n",
    "                if len(linked_taskInds) > 1:\n",
    "                    msgs[1] = sum([m[0] for m in [r_msgs[j][i] for j in linked_taskInds if j != t_key]])\n",
    "                    msg_0 = []\n",
    "                    ts = list(linked_taskInds)\n",
    "                    ts.remove(t_key)\n",
    "\n",
    "                    for k in ts:\n",
    "                        msg_0.append(sum([m[0] for m in [r_msgs[j][i] for j in ts if j != k]])\n",
    "                                     + r_msgs[k][i][1])\n",
    "\n",
    "                    msgs[0] = (0 if msg_0 == [] else max(msg_0))\n",
    "                else:\n",
    "                    msgs[1] = 0\n",
    "\n",
    "                alphas = -sum(msgs.values()) / len(msgs.keys())\n",
    "\n",
    "                msgs_regularised = {d_key: msgs[d_key] + alphas for d_key in msgs.keys()}\n",
    "\n",
    "                old_msg = q_msgs[i][t_key]\n",
    "                if old_msg != {} and any([abs(msgs_regularised[d_key] - old_msg[d_key]) > 10 ** (-5)\n",
    "                                          for d_key in old_msg.keys()]):\n",
    "                    flag = False\n",
    "\n",
    "                q_msgs[i][t_key] = msgs_regularised\n",
    "\n",
    "            if flag:  # agent i sending the same info\n",
    "                q_flags[i] = True\n",
    "\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            break\n",
    "        ###################### SAME thing, using comprehension\n",
    "        #             msgs = {t_key:{d_key:sum([m[d_key] for m in [r_msgs[j][i] for j in linked_taskInds if j != t_key]])\n",
    "        #                            for d_key in linked_taskInds}\n",
    "        #                                 for t_key in linked_taskInds}\n",
    "        #             alphas = {t_key:-sum(msgs[t_key].values())/len(msgs.keys())\n",
    "        #                       for t_key in linked_taskInds}\n",
    "        #             msgs_regularised = {t_key:{d_key:msgs[t_key][d_key] + alphas[t_key]\n",
    "        #                            for d_key in linked_taskInds}\n",
    "        #                                 for t_key in linked_taskInds}\n",
    "        for j in range(0, task_num):\n",
    "            linked_agentInds = t_agentInds[j]\n",
    "            # msg_con = [q_msgs[a][j] for a in linked_agentInds]\n",
    "\n",
    "            com_dict = []\n",
    "            com_rewards = []\n",
    "            dom_com = [[0, 1] if len(a_taskInds[i]) > 1 else [1] for i in linked_agentInds]\n",
    "\n",
    "            for c in itertools.product(*dom_com):\n",
    "                ####### check time bound\n",
    "                if time.time() - start_time >= time_bound:\n",
    "                    r = resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)\n",
    "                ####### check time bound\n",
    "\n",
    "                com_dict.append({linked_agentInds[i]: c[i] for i in range(0, len(c))})\n",
    "                com_rewards.append(\n",
    "                    task_reward(tasks[j], [agents[a_key] for a_key in com_dict[-1].keys() if com_dict[-1][a_key] == 1],\n",
    "                                gamma)\n",
    "                )\n",
    "\n",
    "            flag = True\n",
    "            for a_key in linked_agentInds:\n",
    "\n",
    "                ####### check time bound\n",
    "                if time.time() - start_time >= time_bound:\n",
    "                    r = resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)\n",
    "                ####### check time bound\n",
    "\n",
    "                old_msg = r_msgs[j][a_key]\n",
    "                q_table = []\n",
    "                for c in range(0, len(com_dict)):\n",
    "                    q_table.append(sum([q_msgs[a][j][com_dict[c][a]] for a in linked_agentInds if a != a_key])\n",
    "                                   + com_rewards[c])\n",
    "\n",
    "                r_msgs[j][a_key] = {\n",
    "                    d_key: max([q_table[c] for c in range(0, len(com_dict)) if com_dict[c][a_key] == d_key])\n",
    "                    for d_key in ([0, 1] if len(a_taskInds[a_key]) > 1 else [1])}\n",
    "\n",
    "                if any([abs(r_msgs[j][a_key][d_key] - old_msg[d_key]) > 10 ** (-5) for d_key in old_msg.keys()]):\n",
    "                    flag = False\n",
    "\n",
    "            if flag:  # task j sending the same info\n",
    "                r_flags[j] = True\n",
    "\n",
    "        record_t.append(time.time() - start_time)\n",
    "        r = resultCal(agents, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)        \n",
    "        record_u.append(r[1])\n",
    "\n",
    "    return record_u, record_t   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_DSA(constraints, tasks, agents, probability, time_bound):\n",
    "    converge = False\n",
    "    record_u = []\n",
    "    record_t = []\n",
    "    record_message = []\n",
    "    agent_num = len(agents)\n",
    "    task_num = len(tasks)\n",
    "    a_tasks = constraints[0]\n",
    "    t_agents = constraints[1]\n",
    "    contributions = {}\n",
    "    for j in range(0, task_num):\n",
    "        contributions['towards task ' + str(j)] = list(np.zeros(len(t_agents[j]), int))\n",
    "    received_contribution = {} # zero at the task_num-th is the contribution of an agent assigned to no tasks\n",
    "    for i in range(0, agent_num):\n",
    "        received_contribution['agent ' + str(i)] = list(np.zeros(len(a_tasks[i])+1, int))\n",
    "    movement_values = {}\n",
    "    CS = [[] for j in range(0, task_num+1)]\n",
    "    state = [task_num for i in range(0, agent_num)]\n",
    "    update_t = range(0, task_num)\n",
    "    iter = 0\n",
    "    \n",
    "    is_continue = True\n",
    "    start_time = time.time()\n",
    "    while is_continue:  # > 0:\n",
    "        message_pass_num = 0\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            break\n",
    "        iter += 1\n",
    "\n",
    "        # update agents' allocation state\n",
    "        for j in range(0, task_num):\n",
    "            member_agents = CS[j]\n",
    "            for i in member_agents:\n",
    "                state[i] = int(j)\n",
    "\n",
    "        # tasks calculate agents contribution to them\n",
    "        for j in range(0, task_num):\n",
    "            if j in update_t:\n",
    "                for i in t_agents[j]:\n",
    "                    message_pass_num += 1\n",
    "                    current_coal = CS[j]\n",
    "                    if len(current_coal) == 0:\n",
    "                        coal = [agents[i]]\n",
    "                        add_reward = task_reward(tasks[j], coal, gamma=1)\n",
    "                        ini_contrib = add_reward\n",
    "                    else:\n",
    "                        coal = [agents[mem] for mem in current_coal]\n",
    "                        cur_reward = task_reward(tasks[j], coal, gamma=1)\n",
    "                        if i in current_coal:\n",
    "                            remained_mems = current_coal[:]\n",
    "                            remained_mems.remove(i)\n",
    "                            if len(remained_mems) == 0:\n",
    "                                non_a_reward = 0\n",
    "                            else:\n",
    "                                remain_coal = [agents[remai_mem] for remai_mem in remained_mems]\n",
    "                                non_a_reward = task_reward(tasks[j], remain_coal, gamma=1)\n",
    "                            ini_contrib = cur_reward - non_a_reward\n",
    "                        else:\n",
    "                            coal.append(agents[i])\n",
    "                            add_reward = task_reward(tasks[j], coal, gamma=1)\n",
    "                            ini_contrib = add_reward - cur_reward\n",
    "                    j_index = a_tasks[i].index(j)\n",
    "                    received_contribution['agent ' + str(i)][j_index] = ini_contrib\n",
    "                    i_ind = t_agents[j].index(i)\n",
    "                    contributions['towards task ' + str(j)][i_ind] = ini_contrib\n",
    "\n",
    "        # agents calculate their movement values #\n",
    "        for i in range(0, agent_num):\n",
    "            current_task = state[i]   # the agent's current task\n",
    "            if current_task == task_num:\n",
    "                current_contribution = 0\n",
    "            else:\n",
    "                cur_t_ind = a_tasks[i].index(current_task)\n",
    "                current_contribution = received_contribution['agent ' + str(i)][cur_t_ind]\n",
    "            movement_values['agent ' + str(i)] = [received_contribution['agent ' + str(i)][mess_ind]-current_contribution for mess_ind in range(0, len(received_contribution['agent ' + str(i)]))]\n",
    "\n",
    "        # agents choose their tasks  ##########\n",
    "        update_t = []\n",
    "        max_mv = [[] for i in range(0, agent_num)]\n",
    "        for i in range(0, agent_num):\n",
    "            max_mv[i] = max(movement_values['agent ' + str(i)])\n",
    "            if max_mv[i] > 0:\n",
    "                pro = np.random.random(1)\n",
    "                if pro > 1 - probability:\n",
    "                    old_task = state[i]\n",
    "                    potential_task = []\n",
    "                    max_num = movement_values['agent ' + str(i)].count(max_mv[i])\n",
    "                    first_pos = 0\n",
    "                    for ind in range(max_num):\n",
    "                        new_list = movement_values['agent ' + str(i)][first_pos:]\n",
    "                        potential_task.append(first_pos + new_list.index(max_mv[i]))\n",
    "                        next_pos = new_list.index(max_mv[i]) + 1\n",
    "                        first_pos += next_pos\n",
    "                    choose_t_ind = np.random.randint(len(potential_task))\n",
    "                    choosed_task = a_tasks[i][potential_task[choose_t_ind]]\n",
    "                    # message_pass_num += 1\n",
    "                    CS[choosed_task].append(i)\n",
    "                    update_t.append(choosed_task)\n",
    "                    state[i] = choosed_task\n",
    "                    if old_task != task_num:\n",
    "                        # message_pass_num += 1\n",
    "                        CS[old_task].remove(i)\n",
    "                        update_t.append(old_task)\n",
    "        #  if continue\n",
    "        if max(max_mv) > 0:\n",
    "            is_continue = True\n",
    "        else:\n",
    "            is_continue = False\n",
    "            converge = True\n",
    "        \n",
    "        record_t.append(time.time()- start_time)\n",
    "        #  current system reward    #\n",
    "        ini_task_u = [[] for i in range(0, task_num)]\n",
    "        for j in range(0, task_num):\n",
    "            if len(CS[j]) == 0:\n",
    "                ini_task_u[j] = 0\n",
    "            else:\n",
    "                t_coalition = [agents[c_mem] for c_mem in CS[j]]\n",
    "                ini_task_u[j] = task_reward(tasks[j], t_coalition, gamma=1)\n",
    "        global_u = sum(ini_task_u)\n",
    "        record_u.append(global_u)\n",
    "        record_message.append(message_pass_num)\n",
    "\n",
    "    return record_u, record_t, record_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_disNE(constraints, tasks, agents, time_bound):\n",
    "\n",
    "    converge = False\n",
    "    agent_num = len(agents)\n",
    "    task_num = len(tasks)\n",
    "    a_tasks = constraints[0]\n",
    "    t_agents = constraints[1]\n",
    "\n",
    "    CS = [[] for j in range(0, task_num + 1)]\n",
    "    contributions = {}\n",
    "    for j in range(0, task_num):\n",
    "        contributions['towards task ' + str(j)] = list(np.zeros(len(t_agents[j]), int))\n",
    "    received_contribution = {}  # zero at the task_num-th is the contribution of an agent assigned to no tasks\n",
    "    for i in range(0, agent_num):\n",
    "        received_contribution['agent ' + str(i)] = list(np.zeros(len(a_tasks[i])+1, int))\n",
    "    movement_values = {}\n",
    "\n",
    "    state = [task_num for i in range(0, agent_num)]  # agents' current assignments, initially are no-task (task_num)\n",
    "    iter = 0\n",
    "    record_u = []\n",
    "    record_t = []\n",
    "    record_message = []\n",
    "    update_t = range(0, task_num)\n",
    "    is_continue = True\n",
    "    start_time = time.time()\n",
    "    while is_continue:  # > 0:\n",
    "        message_pass_num = 0\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            break\n",
    "        iter += 1\n",
    "        # update agents' allocation state\n",
    "        for j in update_t:\n",
    "            member_agents = CS[j]\n",
    "            for i in member_agents:\n",
    "                state[i] = int(j)\n",
    "\n",
    "        # tasks calculate agents contribution to them\n",
    "        for j in range(0, task_num):\n",
    "            if j in update_t:\n",
    "                for i in t_agents[j]:\n",
    "                    message_pass_num += 1\n",
    "                    current_coal = CS[j]\n",
    "                    if len(current_coal) == 0:\n",
    "                        coal = [agents[i]]\n",
    "                        add_reward = task_reward(tasks[j], coal, gamma=1)\n",
    "                        ini_contrib = add_reward\n",
    "                    else:\n",
    "                        coal = [agents[mem] for mem in current_coal]\n",
    "                        cur_reward = task_reward(tasks[j], coal, gamma=1)\n",
    "                        if i in current_coal:\n",
    "                            remained_mems = current_coal[:]\n",
    "                            remained_mems.remove(i)\n",
    "                            if len(remained_mems) == 0:\n",
    "                                non_a_reward = 0\n",
    "                            else:\n",
    "                                remain_coal = [agents[remai_mem] for remai_mem in remained_mems]\n",
    "                                non_a_reward = task_reward(tasks[j], remain_coal, gamma=1)\n",
    "                            ini_contrib = cur_reward - non_a_reward\n",
    "                        else:\n",
    "                            coal.append(agents[i])\n",
    "                            add_reward = task_reward(tasks[j], coal, gamma=1)\n",
    "                            ini_contrib = add_reward - cur_reward\n",
    "                    j_index = a_tasks[i].index(j)\n",
    "                    received_contribution['agent ' + str(i)][j_index] = ini_contrib\n",
    "                    i_ind = t_agents[j].index(i)\n",
    "                    contributions['towards task ' + str(j)][i_ind] = ini_contrib\n",
    "\n",
    "        # agents calculate their movement values #\n",
    "        for i in range(0, agent_num):\n",
    "            current_task = state[i]   # the agent's current task\n",
    "            if current_task == task_num:\n",
    "                current_contribution = 0\n",
    "            else:\n",
    "                cur_t_ind = a_tasks[i].index(current_task)\n",
    "                current_contribution = received_contribution['agent ' + str(i)][cur_t_ind]\n",
    "            movement_values['agent ' + str(i)] = [received_contribution['agent ' + str(i)][mess_ind]-current_contribution for mess_ind in range(0, len(received_contribution['agent ' + str(i)]))]\n",
    "\n",
    "        #   agents propose to tasks #\n",
    "        received_proposal = [{'from agents': [], 'proposal values': []} for j in range(0, task_num)]   # the proposals received by tasks\n",
    "        propose_states = {}    # which agents propose to which tasks\n",
    "        propose_agents = []     # which agents make proposals\n",
    "        received_tasks = []  # which tasks receive proposals\n",
    "        max_mv = [[] for i in range(0, agent_num)]\n",
    "        for i in range(0, agent_num):\n",
    "            max_mv[i] = max(movement_values['agent ' + str(i)])\n",
    "            if max_mv[i] > 0:\n",
    "                propose_agents.append(i)\n",
    "                aim_task = []   # aiming tasks are the tasks the agent makes proposal to\n",
    "                max_num = movement_values['agent ' + str(i)].count(max_mv[i])\n",
    "                first_pos = 0\n",
    "                for ind in range(max_num):\n",
    "                    new_list = movement_values['agent ' + str(i)][first_pos:]\n",
    "                    index_add_t = first_pos + new_list.index(max_mv[i])\n",
    "                    act_task = a_tasks[i][index_add_t]\n",
    "                    aim_task.append(act_task)\n",
    "                    next_pos = new_list.index(max_mv[i]) + 1\n",
    "                    first_pos += next_pos\n",
    "                old_task = state[i]\n",
    "                if old_task != task_num:\n",
    "                    aim_task.append(old_task)\n",
    "\n",
    "                message_pass_num += len(aim_task)\n",
    "                propose_states['agent ' + str(i)] = aim_task\n",
    "                received_tasks.append(aim_task)\n",
    "                for j in aim_task:\n",
    "                    received_proposal[j]['from agents'].append(i)\n",
    "                    received_proposal[j]['proposal values'].append(max_mv[i])\n",
    "\n",
    "        # check whether or not to continue  #\n",
    "        if max(max_mv) > 0:\n",
    "            is_continue = True\n",
    "        else:\n",
    "            is_continue = False\n",
    "            converge = True\n",
    "\n",
    "        # tasks send instruction messages to agents #\n",
    "        if is_continue:\n",
    "            #  find out which coalitions received proposal\n",
    "            active_tasks = []\n",
    "            for j in received_tasks:\n",
    "                active_tasks.extend(j)\n",
    "            active_tasks = list(set(active_tasks))\n",
    "\n",
    "            instruction_received = {}\n",
    "            for i in propose_agents:\n",
    "                instruction_received['agent ' + str(i)] = list(np.zeros(len(propose_states['agent ' + str(i)]), int))\n",
    "                message_pass_num += len(propose_states['agent ' + str(i)])\n",
    "\n",
    "            for j in active_tasks:\n",
    "                if j == task_num:\n",
    "                    for a_i in received_proposal[j]['from agents']:\n",
    "                        a_i_index = propose_states['agent ' + str(int(a_i))].index(j)\n",
    "                        instruction_received['agent ' + str(int(a_i))][a_i_index] = 1\n",
    "                else:\n",
    "                    max_pro = max(received_proposal[j]['proposal values'])\n",
    "                    poent_accep_agent = []   # the agents who give the maximum proposal\n",
    "                    poten_num = received_proposal[j]['proposal values'].count(max_pro)\n",
    "                    first_pos = 0\n",
    "                    for ind in range(poten_num):\n",
    "                        new_list = received_proposal[j]['proposal values'][first_pos:]\n",
    "                        index_add_a = first_pos + new_list.index(max_pro)\n",
    "                        act_agent = received_proposal[j]['from agents'][index_add_a]\n",
    "                        poent_accep_agent.append(act_agent)\n",
    "                        next_pos = new_list.index(max_pro) + 1\n",
    "                        first_pos += next_pos\n",
    "                    choosed_agent = np.random.choice(poent_accep_agent)  # the agent index accepted by task j\n",
    "                    acc_t_ind = propose_states['agent '+ str(int(choosed_agent))].index(j)   # the index of task j\n",
    "                    instruction_received['agent '+str(int(choosed_agent))][acc_t_ind] = 1\n",
    "\n",
    "        # agents move to tasks\n",
    "        update_t = []\n",
    "        for i in propose_agents:\n",
    "            accept_num = instruction_received['agent '+str(i)].count(1)\n",
    "            if accept_num == 0:\n",
    "                continue\n",
    "            else:\n",
    "                first_pos = 0\n",
    "                accept_tasks = []  # the index of accept message, which corresponding to the index of sending tasks\n",
    "                for ind in range(accept_num):\n",
    "                    new_list = instruction_received['agent ' + str(i)][first_pos:]\n",
    "                    new_t_ind = first_pos + new_list.index(1)\n",
    "                    act_task = propose_states['agent ' + str(i)][new_t_ind]\n",
    "                    accept_tasks.append(act_task)\n",
    "                    next_pos = new_list.index(1) + 1\n",
    "                    first_pos += next_pos\n",
    "\n",
    "                old_coa = state[i]\n",
    "                if old_coa != task_num:\n",
    "                    old_coa_ind = propose_states['agent '+ str(i)].index(old_coa)\n",
    "                    if instruction_received['agent '+str(i)][old_coa_ind] == 0:  # agent's own task reject its movement\n",
    "                        continue\n",
    "                    else:\n",
    "                        message_pass_num += 1\n",
    "                        accept_tasks.remove(old_coa)  # the other accept-coalitions besides its own coalition\n",
    "                if len(accept_tasks) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    message_pass_num += 1\n",
    "                    choosed_task = np.random.choice(accept_tasks)  # random select a coalition that gives accept message\n",
    "                CS[choosed_task].append(i)\n",
    "                update_t.append(choosed_task)\n",
    "                if old_coa != task_num:\n",
    "                    de_i_ind = CS[old_coa].index(i)\n",
    "                    del CS[old_coa][de_i_ind]\n",
    "                    update_t.append(old_coa)\n",
    "        \n",
    "        record_t.append(time.time()-start_time)\n",
    "        # current system reward #\n",
    "        ini_task_u = [[] for j in range(0, task_num)]\n",
    "        for j in range(0, task_num):\n",
    "            if len(CS[j]) == 0:\n",
    "                ini_task_u[j] = 0\n",
    "            else:\n",
    "                t_coalition = [agents[c_mem] for c_mem in CS[j]]\n",
    "                ini_task_u[j] = task_reward(tasks[j], t_coalition, gamma=1)\n",
    "        global_u = sum(ini_task_u)\n",
    "        record_u.append(global_u)\n",
    "        record_message.append(message_pass_num)\n",
    "\n",
    "    return record_u, record_t, record_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_record(record, filename, typ):\n",
    "    with open(filename, 'a') as f:\n",
    "        if typ != '':\n",
    "            json.dump(record, f, default = typ)\n",
    "        else:\n",
    "            json.dump(record, f)\n",
    "        f.write('\\n')\n",
    "        # f.write(os.linesep)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSA time: 0.28623461723327637 7143\n",
      "disNE time: 0.12566113471984863 7174\n",
      "BnBFMS time: 435.6629014015198 7094\n"
     ]
    }
   ],
   "source": [
    "run_num = 1\n",
    "probability = 0.7\n",
    "time_bound = 300\n",
    "capNum = 10\n",
    "max_capNum_task = 10\n",
    "max_capNum_agent = 10\n",
    "max_capVal = 10\n",
    "capabilities = list(range(0, capNum))\n",
    "a_min_edge = 1\n",
    "task_num = 100\n",
    "agent_num = 2 * task_num\n",
    "\n",
    "# t_max_edge = 6\n",
    "# min_t_num = 2\n",
    "# max_t_num = 2\n",
    "# agent_num = 4\n",
    "# agents = np.array([[0, 0, 0, 7, 6], [4, 3, 8, 8, 4], [0, 9, 8, 0, 0], [4, 9, 0, 7, 0]])\n",
    "# tasks = np.array([[0, 1, 2], [0, 3, 4]])\n",
    "# constraints = ([[0, 1], [0, 1], [0, 1], [0, 1]], [[0, 1, 2, 3], [0, 1, 2, 3]])\n",
    "\n",
    "\n",
    "t_max_edge = 0.04 * task_num\n",
    "tasks = gen_tasks(task_num, max_capNum_task, capabilities)\n",
    "constraints = gen_constraints(agent_num, task_num, 1, a_min_edge, t_max_edge)\n",
    "## caps_lists: capabilities the agent can provide; agents: the value of the agent provide the capabilities\n",
    "caps_lists, agents = gen_agents(constraints, tasks, max_capNum_agent, capabilities, max_capVal)\n",
    "\n",
    "# a_tasks = constraints[0]\n",
    "# t_agents = constraints[1]\n",
    "# for i in range(0, agent_num):\n",
    "#     a_tasks[i].append(task_num)\n",
    "# t_agents.append(list(range(0, agent_num)))\n",
    "\n",
    "result = {\"task_num\": task_num, \"agent_num\": agent_num}\n",
    "\n",
    "\n",
    "# r = random(agents, tasks,constraints, gamma=1 )\n",
    "# alloc = r[0]\n",
    "# result['rand'] = r[1]\n",
    "# print(\"task_number: \", task_num, 'rand result',result['rand'])\n",
    "\n",
    "start = time.time()\n",
    "dsa_u, dsa_t, dsa_msg_num = embed_DSA(constraints, tasks, agents, probability, time_bound)\n",
    "end = time.time()\n",
    "result['dsa_u'] = dsa_u\n",
    "result['dsa_t'] = dsa_t\n",
    "result['dsa_msg'] = dsa_msg_num\n",
    "print(\"DSA time:\", end-start, dsa_u[-1])\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "disNE_u, disNE_t, disNE_msg_num = embed_disNE(constraints, tasks, agents, time_bound)\n",
    "end = time.time()\n",
    "result['disNE_u'] = disNE_u\n",
    "result['disNE_t'] = disNE_t\n",
    "result['DisNE_msg'] = disNE_msg_num\n",
    "print(\"disNE time:\", end-start, disNE_u[-1])\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "new_con = OPD(agents, tasks, constraints, gamma=1)\n",
    "BnBFMS_u, BnBFMS_t = FMS(agents, tasks, new_con, gamma=1, time_bound=time_bound)\n",
    "end = time.time()\n",
    "result['BnBFMS_u'] = BnBFMS_u\n",
    "result['BnBFMS_t'] = BnBFMS_t\n",
    "print(\"BnBFMS time:\", end-start, BnBFMS_u[-1])\n",
    "\n",
    "\n",
    "# #         append data and result\n",
    "# files = {'cap_mono2': [result, '']} #\n",
    "# for filename in list(files.keys()):\n",
    "#     append_record(files[filename][0], filename, typ=files[filename][1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
