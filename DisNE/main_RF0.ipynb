{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "from functools import reduce # python3 compatibility\n",
    "from operator import mul\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for generating environment with capability\n",
    "# generating task\n",
    "def gen_tasks_RF(task_num, t_agents, max_reward = 100): # task reward DB, for each task, each coaltion value is a random number between (0,100)\n",
    "    tasks = [] # tasks is a list of task reward dictinoary, key represents the agent allocation in binary sum, value is a random integer\n",
    "    for j in range(0, task_num):\n",
    "        if j == task_num-1:\n",
    "            coalitions = [(-1, 0)]\n",
    "            tasks.append({key: value for (key, value) in coalitions})\n",
    "        else:\n",
    "            coalitions = list(itertools.chain(*[itertools.combinations(t_agents[j],i+1) for i,_ in enumerate(t_agents[j])]))\n",
    "            dict_list = [(sum([2**a for a in com]), np.random.randint(1, max_reward+1)) for com in coalitions]\n",
    "            tasks.append({key: value for (key, value) in dict_list})\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def gen_tasks_RF2(task_num): # task reward DB, for each task, each coaltion value is a random number between (0,100)\n",
    "    return [{} for j in range(0,task_num)]\n",
    "\n",
    "\n",
    "def gen_constraints(agent_num, task_num, power=1, a_min_edge=2,\n",
    "                    t_max_edge=5):  # power is the inforce you put in the probabilities\n",
    "\n",
    "    # the maximum tasks an agent could work on depends on the number of tasks available (e.g, if |T| = 1/2|A|, the roughly each agent can work on two tasks)\n",
    "    # calculate the max and min edges for agents\n",
    "    seats = math.floor(t_max_edge * task_num)\n",
    "    a_taskInds = [[] for i in range(0, agent_num)]\n",
    "    t_counter = [0 for j in range(0, task_num)]  # each indicate the current number of agents on the task\n",
    "\n",
    "    ## generating the number of tasks the agents could work on.\n",
    "    a_taskNums = []\n",
    "    for i in range(0, agent_num):\n",
    "        a_max_edge = min((seats - (agent_num - 1 - i) * a_min_edge), t_max_edge)\n",
    "        a_min_edge = min(a_min_edge, a_max_edge)\n",
    "        a_taskNums.append(\n",
    "            np.random.randint(a_min_edge, a_max_edge + 1))  # indicate the number of task the agent could work on\n",
    "        seats -= a_taskNums[i]\n",
    "\n",
    "    t_indexes = [j for j in range(0, task_num) if\n",
    "                 t_counter[j] < t_max_edge]  # make sure no further draw for those reached the maximum limit.\n",
    "    for i in range(0, agent_num):\n",
    "        if any([tc == 0 for tc in t_counter]):\n",
    "            t_prob = [(math.e ** (t_max_edge - t_counter[j])) ** power for j in\n",
    "                      t_indexes]  # power is used to manify the probability\n",
    "            sum_prob = sum(t_prob)\n",
    "            t_prop_2 = [prop / sum_prob for prop in t_prob]\n",
    "\n",
    "            # draw tasks accounting to their current allocations\n",
    "            a_taskInds[i] = list(np.random.choice(t_indexes, min(a_taskNums[i], len(t_indexes)), replace=False,\n",
    "                                                  p=[prop / sum_prob for prop in t_prob]))\n",
    "            # increase the chosen task counters\n",
    "        else:\n",
    "            a_taskInds[i] = list(np.random.choice(t_indexes, min(a_taskNums[i], len(t_indexes)), replace=False))\n",
    "\n",
    "        for j in a_taskInds[i]:\n",
    "            t_counter[j] += 1\n",
    "        t_indexes = [j for j in range(0, task_num) if\n",
    "                     t_counter[j] < t_max_edge]  # make sure no further draw for those reached the maximum limit.\n",
    "\n",
    "    # get also the list of agents for each task\n",
    "    t_agents = [[i for i in range(0, agent_num) if j in a_taskInds[i]] for j in range(0, task_num)]\n",
    "\n",
    "    return a_taskInds, t_agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_reward_RF(task, coalition, gamma=1, max_reward=100): # task is a dict (reward DB), coalition is a list of agents (indexes)\n",
    "    key = sum([2**int(coalition[i]) for i in range(0,len(coalition))])\n",
    "    if key in task.keys():\n",
    "        return task[key]\n",
    "    else:\n",
    "        task[key] = np.random.randint(0,max_reward+1)\n",
    "        return task[key]\n",
    "    \n",
    "\n",
    "def sys_rewards_tasks(tasks, CS, gamma = 1): # CS is a list of coalitions\n",
    "    return sum([task_reward_RF(tasks[j],CS[j],gamma) for j in range(0,len(tasks))])\n",
    "\n",
    "\n",
    "\n",
    "def alloc_to_CS(tasks,alloc):\n",
    "    task_num = len(tasks)\n",
    "    CS = [[] for j in range(0, len(tasks))]\n",
    "    for i in range(0,len(alloc)):\n",
    "        if alloc[i]< task_num: # means allocated (!=task_num)\n",
    "            CS[alloc[i]].append(i)\n",
    "    return CS\n",
    "\n",
    "\n",
    "def resultCal_RF(agent_num, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma=1):\n",
    "    a_taskInds = constraints[0]\n",
    "    task_num = len(tasks)\n",
    "\n",
    "    a_msg_sum = [{d_key: sum([r_msgs[j][i][0] for j in a_taskInds[i] if j != d_key])\n",
    "                         + r_msgs[d_key][i][1] for d_key in a_taskInds[i]}\n",
    "                 for i in range(0, agent_num)]\n",
    "\n",
    "    alloc = [max(ams, key=ams.get) if ams != {} else task_num for ams in a_msg_sum]\n",
    "    return alloc, sys_rewards_tasks(tasks, alloc_to_CS(tasks, alloc), gamma), iteration, iter_over, converge\n",
    "\n",
    "\n",
    "# Agent contribution\n",
    "def agent_con_RF(task, j, a_tasks, query_agentIndex, cur_coalition, gamma=1): # cur_coalition is a list of agents (indexes)\n",
    "    if j not in a_tasks[query_agentIndex]:\n",
    "        return -1000\n",
    "    else:\n",
    "        if query_agentIndex in cur_coalition:\n",
    "            new_coalition = list(cur_coalition)\n",
    "            new_coalition.remove(query_agentIndex)\n",
    "            return task_reward_RF(task,cur_coalition,gamma) - task_reward_RF(task,new_coalition,gamma)\n",
    "        else:\n",
    "            return task_reward_RF(task,cur_coalition+[query_agentIndex],gamma) - task_reward_RF(task,cur_coalition,gamma)\n",
    "\n",
    "\n",
    "def aim_tasks(movement_values, a_tasks, a_index):\n",
    "    max_mv = max(movement_values['agent ' + str(a_index)])\n",
    "    target_tasks = []  # aiming tasks are the tasks the agent makes proposal to\n",
    "    max_num = movement_values['agent ' + str(a_index)].count(max_mv)\n",
    "    first_pos = 0\n",
    "    for ind in range(max_num):\n",
    "        new_list = movement_values['agent ' + str(a_index)][first_pos:]\n",
    "        index_add_t = first_pos + new_list.index(max_mv)\n",
    "        act_task = a_tasks[a_index][index_add_t]\n",
    "        target_tasks.append(act_task)\n",
    "        next_pos = new_list.index(max_mv) + 1\n",
    "        first_pos += next_pos\n",
    "    return target_tasks\n",
    "\n",
    "\n",
    "def accepted_tasks(instruction_received, propose_states, a_index):\n",
    "    accept_num = instruction_received['agent ' + str(a_index)].count(1)\n",
    "    accept_tasks = []  # the index of accept message, which corresponding to the index of sending tasks\n",
    "    first_pos = 0\n",
    "    for ind in range(accept_num):\n",
    "        new_list = instruction_received['agent ' + str(a_index)][first_pos:]\n",
    "        new_t_ind = first_pos + new_list.index(1)\n",
    "        act_task = propose_states['agent ' + str(a_index)][new_t_ind]\n",
    "        accept_tasks.append(act_task)\n",
    "        next_pos = new_list.index(1) + 1\n",
    "        first_pos += next_pos\n",
    "    return accept_tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OPD_RF(agent_num, tasks, constraints, gamma):\n",
    "    task_num = len(tasks)\n",
    "    a_taskInds = [list(con) for con in constraints[0]]\n",
    "    t_agentInds = [list(con) for con in constraints[1]]\n",
    "\n",
    "    a_ubs = [[0 for j in a_taskInds[i]] for i in range(0, agent_num)]\n",
    "    a_lbs = [[0 for j in a_taskInds[i]] for i in range(0, agent_num)]\n",
    "\n",
    "    for j in range(0, task_num):\n",
    "\n",
    "        linked_agentInds = t_agentInds[j]\n",
    "        com_dict = []\n",
    "        com_rewards = []\n",
    "        for c in itertools.product(*[[0, 1] for i in linked_agentInds]):\n",
    "            com_dict.append({linked_agentInds[i]: c[i] for i in range(0, len(c))})\n",
    "            com_rewards.append(\n",
    "                task_reward_RF(tasks[j], [a_key for a_key in com_dict[-1].keys() if com_dict[-1][a_key] == 1], gamma)\n",
    "            )\n",
    "\n",
    "        for i in t_agentInds[j]:\n",
    "            t_ind = a_taskInds[i].index(j)\n",
    "            cons_j = [com_rewards[c]\n",
    "                      for c in range(0, len(com_dict)) if com_dict[c][i] == 1]\n",
    "\n",
    "            a_lbs[i][t_ind] = min(cons_j)\n",
    "            a_ubs[i][t_ind] = max(cons_j)\n",
    "\n",
    "    for i in range(0, agent_num):\n",
    "        t_flag = [True for j in a_taskInds[i]]\n",
    "        for t_ind in range(0, len(a_taskInds[i])):\n",
    "            for t2_ind in range(0, len(a_taskInds[i])):\n",
    "                if t_ind != t2_ind and a_ubs[i][t_ind] < a_lbs[i][t2_ind]:\n",
    "                    t_flag[t_ind] = False\n",
    "                    break\n",
    "\n",
    "        for t_ind in range(0, len(t_flag)):\n",
    "            if not t_flag[t_ind]:\n",
    "                t_agentInds[a_taskInds[i][t_ind]].remove(i)\n",
    "\n",
    "        new_a_taskInds = [a_taskInds[i][t_ind]\n",
    "                          for t_ind in range(0, len(a_taskInds[i])) if t_flag[t_ind]]\n",
    "        a_taskInds[i] = new_a_taskInds\n",
    "    return a_taskInds, t_agentInds\n",
    "\n",
    "\n",
    "def FMS_RF(agent_num, tasks, constraints, gamma, time_bound):\n",
    "    converge = False\n",
    "    iter_over = False\n",
    "    start_time = time.time()\n",
    "    a_taskInds = constraints[0]\n",
    "    t_agentInds = constraints[1]\n",
    "    task_num = len(tasks)\n",
    "\n",
    "    q_msgs = [{t_key: {} for t_key in a_taskInds[i]} for i in range(0, agent_num)]\n",
    "    r_msgs = [\n",
    "        {t_agentInds[j][i]: ({1: -100} if len(a_taskInds[t_agentInds[j][i]]) == 1 else {key: -100 for key in [0, 1]})\n",
    "         for i in range(0, len(t_agentInds[j]))}\n",
    "        for j in range(0, task_num)]\n",
    "\n",
    "    q_flags = [False for i in range(0, agent_num)]\n",
    "    r_flags = [False for j in range(0, task_num)]\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            return resultCal_RF(agent_num, tasks, constraints, r_msgs, q_msgs, iteration, iter_over, converge, gamma)\n",
    "        iteration += 1\n",
    "\n",
    "        if iteration > agent_num + task_num:\n",
    "            iter_over = True\n",
    "            return resultCal_RF(agent_num, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)\n",
    "\n",
    "        if all(q_flags) and all(r_flags):  # converge, msgs are all the same.\n",
    "            converge = True\n",
    "            break\n",
    "        for i in range(0, agent_num):\n",
    "            linked_taskInds = a_taskInds[i]\n",
    "\n",
    "            flag = True\n",
    "            for t_key in linked_taskInds:\n",
    "\n",
    "                ####### check time bound\n",
    "                if time.time() - start_time >= time_bound:\n",
    "                    return resultCal_RF(agent_num, tasks, constraints, r_msgs, iteration, iter_over, converge,\n",
    "                                     gamma)\n",
    "                ####### check time bound\n",
    "                msgs = {}\n",
    "\n",
    "                if len(linked_taskInds) > 1:\n",
    "                    msgs[1] = sum([m[0] for m in [r_msgs[j][i] for j in linked_taskInds if j != t_key]])\n",
    "                    msg_0 = []\n",
    "                    ts = list(linked_taskInds)\n",
    "                    ts.remove(t_key)\n",
    "\n",
    "                    for k in ts:\n",
    "                        msg_0.append(sum([m[0] for m in [r_msgs[j][i] for j in ts if j != k]])\n",
    "                                     + r_msgs[k][i][1])\n",
    "\n",
    "                    msgs[0] = (0 if msg_0 == [] else max(msg_0))\n",
    "                else:\n",
    "                    msgs[1] = 0\n",
    "\n",
    "                alphas = -sum(msgs.values()) / len(msgs.keys())\n",
    "\n",
    "                msgs_regularised = {d_key: msgs[d_key] + alphas for d_key in msgs.keys()}\n",
    "\n",
    "                old_msg = q_msgs[i][t_key]\n",
    "                if old_msg != {} and any([abs(msgs_regularised[d_key] - old_msg[d_key]) > 10 ** (-5)\n",
    "                                          for d_key in old_msg.keys()]):\n",
    "                    flag = False\n",
    "\n",
    "                q_msgs[i][t_key] = msgs_regularised\n",
    "\n",
    "            if flag:  # agent i sending the same info\n",
    "                q_flags[i] = True\n",
    "\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            break\n",
    "        ###################### SAME thing, using comprehension\n",
    "        #             msgs = {t_key:{d_key:sum([m[d_key] for m in [r_msgs[j][i] for j in linked_taskInds if j != t_key]])\n",
    "        #                            for d_key in linked_taskInds}\n",
    "        #                                 for t_key in linked_taskInds}\n",
    "        #             alphas = {t_key:-sum(msgs[t_key].values())/len(msgs.keys())\n",
    "        #                       for t_key in linked_taskInds}\n",
    "        #             msgs_regularised = {t_key:{d_key:msgs[t_key][d_key] + alphas[t_key]\n",
    "        #                            for d_key in linked_taskInds}\n",
    "        #                                 for t_key in linked_taskInds}\n",
    "        for j in range(0, task_num):\n",
    "            linked_agentInds = t_agentInds[j]\n",
    "            msg_con = [q_msgs[a][j] for a in linked_agentInds]\n",
    "\n",
    "            com_dict = []\n",
    "            com_rewards = []\n",
    "            dom_com = [[0, 1] if len(a_taskInds[i]) > 1 else [1] for i in linked_agentInds]\n",
    "\n",
    "            for c in itertools.product(*dom_com):\n",
    "                ####### check time bound\n",
    "                if time.time() - start_time >= time_bound:\n",
    "                    return resultCal_RF(agent_num, tasks, constraints, r_msgs, iteration, iter_over, converge,\n",
    "                                     gamma)\n",
    "                ####### check time bound\n",
    "\n",
    "                com_dict.append({linked_agentInds[i]: c[i] for i in range(0, len(c))})\n",
    "                com_rewards.append(\n",
    "                    task_reward_RF(tasks[j], [a_key for a_key in com_dict[-1].keys() if com_dict[-1][a_key] == 1], gamma)\n",
    "                )\n",
    "\n",
    "            flag = True\n",
    "            for a_key in linked_agentInds:\n",
    "\n",
    "                ####### check time bound\n",
    "                if time.time() - start_time >= time_bound:\n",
    "                    return resultCal_RF(agent_num, tasks, constraints, r_msgs, iteration, iter_over, converge,\n",
    "                                     gamma)\n",
    "                ####### check time bound\n",
    "\n",
    "                old_msg = r_msgs[j][a_key]\n",
    "                q_table = []\n",
    "                for c in range(0, len(com_dict)):\n",
    "                    q_table.append(sum([q_msgs[a][j][com_dict[c][a]] for a in linked_agentInds if a != a_key])\n",
    "                                   + com_rewards[c])\n",
    "\n",
    "                r_msgs[j][a_key] = {\n",
    "                    d_key: max([q_table[c] for c in range(0, len(com_dict)) if com_dict[c][a_key] == d_key])\n",
    "                    for d_key in ([0, 1] if len(a_taskInds[a_key]) > 1 else [1])}\n",
    "\n",
    "                if any([abs(r_msgs[j][a_key][d_key] - old_msg[d_key]) > 10 ** (-5) for d_key in old_msg.keys()]):\n",
    "                    flag = False\n",
    "\n",
    "            if flag:  # task j sending the same info\n",
    "                r_flags[j] = True\n",
    "\n",
    "    return resultCal_RF(agent_num, tasks, constraints, r_msgs, iteration, iter_over, converge, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSA_RF(constraints, tasks, agent_num, probability, time_bound):\n",
    "    converge = False\n",
    "    task_num = len(tasks)\n",
    "    a_tasks = copy.deepcopy(constraints[0])\n",
    "    [a_tasks[member].append(task_num) for member in range(0, agent_num)]\n",
    "    t_agents = constraints[1]\n",
    "    received_contribution = {} # zero at the task_num-th is the contribution of an agent assigned to no tasks\n",
    "    for i in range(0, agent_num):\n",
    "        received_contribution['agent ' + str(i)] = list(np.zeros(len(a_tasks[i]), int))\n",
    "    movement_values = {}\n",
    "    CS = [[] for j in range(0, task_num+1)]\n",
    "    state = [task_num for i in range(0, agent_num)]\n",
    "    update_t = range(0, task_num)\n",
    "    iter = 0\n",
    "    message_pass_num = 0\n",
    "    is_continue = True\n",
    "    start_time = time.time()\n",
    "    while is_continue:  # > 0:\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            break\n",
    "        iter += 1\n",
    "\n",
    "        # update agents' allocation state\n",
    "        for j in range(0, task_num):\n",
    "            member_agents = CS[j]\n",
    "            for i in member_agents:\n",
    "                state[i] = int(j)\n",
    "\n",
    "        # tasks calculate agents contribution to them\n",
    "        for j in range(0, task_num):\n",
    "            if j in update_t:\n",
    "                ini_con_list = []\n",
    "                for i in t_agents[j]:\n",
    "                    message_pass_num += 1\n",
    "                    current_coal = CS[j]\n",
    "                    if len(current_coal) == 0:\n",
    "                        ini_contrib = task_reward_RF(tasks[j], [i], max_reward=100)\n",
    "                    else:\n",
    "                        coal = [mem for mem in current_coal]\n",
    "                        cur_reward = task_reward_RF(tasks[j], coal, gamma=1)\n",
    "                        if i in current_coal:\n",
    "                            remained_mems = current_coal[:]\n",
    "                            remained_mems.remove(i)\n",
    "                            if len(remained_mems) == 0:\n",
    "                                non_a_reward = 0\n",
    "                            else:\n",
    "                                remain_coal = [remai_mem for remai_mem in remained_mems]\n",
    "                                non_a_reward = task_reward_RF(tasks[j], remain_coal, gamma=1)\n",
    "                            ini_contrib = cur_reward - non_a_reward\n",
    "                        else:\n",
    "                            coal.append(i)\n",
    "                            add_reward = task_reward_RF(tasks[j], coal, gamma=1)\n",
    "                            ini_contrib = add_reward - cur_reward\n",
    "                    j_index = a_tasks[i].index(j)\n",
    "                    received_contribution['agent ' + str(i)][j_index] = ini_contrib\n",
    "                    i_ind = t_agents[j].index(i)\n",
    "\n",
    "        # agents calculate their movement values #\n",
    "        for i in range(0, agent_num):\n",
    "            current_task = state[i]   # the agent's current task\n",
    "            if current_task == task_num:\n",
    "                current_contribution = 0\n",
    "            else:\n",
    "                cur_t_ind = a_tasks[i].index(current_task)\n",
    "                current_contribution = received_contribution['agent ' + str(i)][cur_t_ind]\n",
    "            movement_values['agent ' + str(i)] = [received_contribution['agent ' + str(i)][mess_ind]-current_contribution for mess_ind in range(0, len(received_contribution['agent ' + str(i)]))]\n",
    "\n",
    "        # agents choose their tasks  ##########\n",
    "        update_t = []\n",
    "        max_mv = [[] for i in range(0, agent_num)]\n",
    "        for i in range(0, agent_num):\n",
    "            max_mv[i] = max(movement_values['agent ' + str(i)])\n",
    "            if max_mv[i] > 0:\n",
    "                pro = np.random.random(1)\n",
    "                if pro > 1 - probability:\n",
    "                    old_task = state[i]\n",
    "                    potential_task = []\n",
    "                    max_num = movement_values['agent ' + str(i)].count(max_mv[i])\n",
    "                    first_pos = 0\n",
    "                    for ind in range(max_num):\n",
    "                        new_list = movement_values['agent ' + str(i)][first_pos:]\n",
    "                        poten_ind = first_pos + new_list.index(max_mv[i])\n",
    "                        potential_task.append(a_tasks[i][poten_ind])\n",
    "                        next_pos = new_list.index(max_mv[i]) + 1\n",
    "                        first_pos += next_pos\n",
    "                    choose_t_ind = np.random.randint(len(potential_task))\n",
    "                    choosed_task = potential_task[choose_t_ind]\n",
    "                    CS[choosed_task].append(i)\n",
    "                    update_t.append(choosed_task)\n",
    "                    state[i] = choosed_task\n",
    "                    if old_task != task_num:\n",
    "                        CS[old_task].remove(i)\n",
    "                        update_t.append(old_task)\n",
    "        #  if continue\n",
    "        if max(max_mv) > 0:\n",
    "            is_continue = True\n",
    "        else:\n",
    "            is_continue = False\n",
    "            converge = True\n",
    "\n",
    "    #  current system reward    #\n",
    "    ini_task_u = [[] for i in range(0, task_num)]\n",
    "    for j in range(0, task_num):\n",
    "        if len(CS[j]) == 0:\n",
    "            ini_task_u[j] = 0\n",
    "        else:\n",
    "            t_coalition = [c_mem for c_mem in CS[j]]\n",
    "            ini_task_u[j] = task_reward_RF(tasks[j], t_coalition, gamma=1)\n",
    "    global_u = sum(ini_task_u)\n",
    "\n",
    "    return global_u, iter, message_pass_num, converge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disNE_RF(constraints, tasks, agent_num, time_bound, CS=[]):\n",
    "    converge = False\n",
    "    task_num = len(tasks)\n",
    "    a_tasks = copy.deepcopy(constraints[0])\n",
    "    t_agents = copy.deepcopy(constraints[1])\n",
    "    t_agents.append(list(range(0, agent_num)))\n",
    "    \n",
    "    if CS==[]:\n",
    "        CS = [[] for j in range(0, task_num+1)]\n",
    "        CS[task_num] = list(range(0, agent_num))\n",
    "\n",
    "    received_contribution = {} # zero at the task_num-th is the contribution of an agent assigned to no tasks\n",
    "    for i in range(0, agent_num):\n",
    "        received_contribution['agent ' + str(i)] = list(np.zeros(len(a_tasks[i]), int))\n",
    "    movement_values = {}\n",
    "    \n",
    "    state = [task_num for i in range(0, agent_num)]\n",
    "    update_t = range(0, task_num)\n",
    "    iter = 0\n",
    "    message_pass_num = 0\n",
    "    is_continue = True\n",
    "    start_time = time.time()\n",
    "    while is_continue:  # > 0:\n",
    "        if time.time() - start_time >= time_bound:\n",
    "            break\n",
    "        iter += 1\n",
    "\n",
    "        # update agents' allocation state\n",
    "        for j in range(0, task_num):\n",
    "            member_agents = CS[j]\n",
    "            for i in member_agents:\n",
    "                state[i] = int(j)\n",
    "\n",
    "        # tasks calculate agents contribution to them\n",
    "        for j in range(0, task_num):\n",
    "            if j in update_t:\n",
    "                ini_con_list = []\n",
    "                for i in t_agents[j]:\n",
    "                    message_pass_num += 1\n",
    "                    current_coal = CS[j]\n",
    "                    if len(current_coal) == 0:\n",
    "                        ini_contrib = task_reward_RF(tasks[j], [i], max_reward=100)\n",
    "                    else:\n",
    "                        coal = [mem for mem in current_coal]\n",
    "                        cur_reward = task_reward_RF(tasks[j], coal, gamma=1)\n",
    "                        if i in current_coal:\n",
    "                            remained_mems = current_coal[:]\n",
    "                            remained_mems.remove(i)\n",
    "                            if len(remained_mems) == 0:\n",
    "                                non_a_reward = 0\n",
    "                            else:\n",
    "                                remain_coal = [remai_mem for remai_mem in remained_mems]\n",
    "                                non_a_reward = task_reward_RF(tasks[j], remain_coal, gamma=1)\n",
    "                            ini_contrib = cur_reward - non_a_reward\n",
    "                        else:\n",
    "                            coal.append(i)\n",
    "                            add_reward = task_reward_RF(tasks[j], coal, gamma=1)\n",
    "                            ini_contrib = add_reward - cur_reward\n",
    "                    j_index = a_tasks[i].index(j)\n",
    "                    received_contribution['agent ' + str(i)][j_index] = ini_contrib\n",
    "                    i_ind = t_agents[j].index(i)\n",
    "\n",
    "        # agents calculate their movement values #\n",
    "        for i in range(0, agent_num):\n",
    "            # print('i: ', i)\n",
    "            current_task = state[i]  # the agent's current task\n",
    "            if current_task == task_num:\n",
    "                current_contribution = 0\n",
    "            else:\n",
    "                cur_t_ind = a_tasks[i].index(current_task)\n",
    "                current_contribution = received_contribution['agent ' + str(i)][cur_t_ind]\n",
    "            movement_values['agent ' + str(i)] = [received_contribution['agent ' + str(i)][mess_ind] - current_contribution for mess_ind in\n",
    "                range(0, len(received_contribution['agent ' + str(i)]))]\n",
    "\n",
    "\n",
    "        max_mv = [max(movement_values['agent ' + str(i)]) for i in range(0, agent_num)]\n",
    "        # check whether or not to continue  #\n",
    "        if max(max_mv) <= 0:  # in this case, no agent will propose\n",
    "            is_continue = False\n",
    "            converge = True\n",
    "        if is_continue:\n",
    "            # agents propose to tasks #\n",
    "            received_proposal = [{'from agents': [], 'proposal values': []} for j in range(0, task_num)]  # received proposals\n",
    "            propose_states = {}  # which agents propose to which tasks\n",
    "            propose_agents = []  # which agents make proposals\n",
    "            received_tasks = []  # which tasks receive proposals\n",
    "            for i in range(0, agent_num):\n",
    "                if max_mv[i] > 0:\n",
    "                    propose_agents.append(i)\n",
    "                    pick_tasks = [k for k, x in enumerate(movement_values['agent ' + str(i)]) if x == max_mv[i]]\n",
    "                    aim_tasks = [a_tasks[i][k] for k in pick_tasks]\n",
    "                    old_task = state[i]\n",
    "                    if old_task != task_num:\n",
    "                        aim_tasks.append(old_task)\n",
    "                    propose_states['agent ' + str(i)] = aim_tasks\n",
    "                    received_tasks.append(aim_tasks)\n",
    "                    for j in aim_tasks:\n",
    "                        received_proposal[j]['from agents'].append(i)\n",
    "                        received_proposal[j]['proposal values'].append(max_mv[i])\n",
    "                    message_pass_num += len(aim_tasks)\n",
    "\n",
    "\n",
    "            #  find out which coalitions received proposal\n",
    "            active_tasks = []\n",
    "            for j in received_tasks:\n",
    "                active_tasks.extend(j)\n",
    "            active_tasks = list(set(active_tasks))\n",
    "            # tasks send instruction messages to agents #\n",
    "            instruction_received = {}  # instruction received by the proposed agents\n",
    "            for i in propose_agents:\n",
    "                instruction_received['agent ' + str(i)] = [0] * len(propose_states['agent ' + str(i)])  # 0: reject, 1: accept\n",
    "\n",
    "            for j in active_tasks:\n",
    "                message_pass_num += len(received_proposal[j]['from agents'])\n",
    "                max_pro = max(received_proposal[j]['proposal values'])\n",
    "                candi_agents = [k for k, x in enumerate(received_proposal[j]['proposal values']) if x == max_pro]\n",
    "                poent_accep_agents = [received_proposal[j]['from agents'][k] for k in\n",
    "                                      candi_agents]  # the agents who give the maximum proposal\n",
    "                choosed_agent = np.random.choice(poent_accep_agents)  # the agent index accepted by task j\n",
    "                acc_t_ind = propose_states['agent ' + str(int(choosed_agent))].index(j)  # the index of task j\n",
    "                instruction_received['agent ' + str(int(choosed_agent))][acc_t_ind] = 1\n",
    "\n",
    "            # agents move to tasks\n",
    "            update_t = []\n",
    "            for i in propose_agents:\n",
    "                accept_num = instruction_received['agent ' + str(i)].count(1)\n",
    "                if accept_num == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    accept_ind = [k for k, x in enumerate(instruction_received['agent ' + str(i)]) if x == 1]\n",
    "                    accept_tasks = [propose_states['agent ' + str(i)][k] for k in accept_ind]\n",
    "                    ########### moving condition ############\n",
    "                    # i) the agent has not been allocated and it receives 1 (accept) from its target-task(s).\n",
    "                    # ii) the agent has a current task and it receives 1 from both its target-task(s) and its current task.\n",
    "                    old_coa = state[i]\n",
    "                    if old_coa != task_num:\n",
    "                        old_coa_ind = propose_states['agent ' + str(i)].index(old_coa)\n",
    "                        if instruction_received['agent ' + str(i)][\n",
    "                            old_coa_ind] == 0:  # the agent's own task reject its movement\n",
    "                            continue\n",
    "                        else:\n",
    "                            accept_tasks.remove(old_coa)  # the other accept-coalitions besides its own coalition\n",
    "                    if len(accept_tasks) == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        choosed_task = np.random.choice(accept_tasks)  # random select a coalition that gives accept message\n",
    "                        CS[choosed_task].append(i)\n",
    "                        CS[old_coa].remove(i)\n",
    "                        message_pass_num += 1\n",
    "                        update_t.append(choosed_task)\n",
    "                        if old_coa != task_num:\n",
    "                            message_pass_num += 1\n",
    "                            update_t.append(old_coa)\n",
    "\n",
    "    # current system reward #\n",
    "    ini_task_u = [[] for j in range(0, task_num)]\n",
    "    for j in range(0, task_num):\n",
    "        if len(CS[j]) == 0:\n",
    "            ini_task_u[j] = 0\n",
    "        else:\n",
    "            t_coalition = [c_mem for c_mem in CS[j]]\n",
    "            ini_task_u[j] = task_reward_RF(tasks[j], t_coalition, gamma=1)\n",
    "    global_u = sum(ini_task_u)\n",
    "\n",
    "    return global_u, iter, message_pass_num, converge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(agent_num,tasks,constraints, gamma = 1):\n",
    "    task_num = len(tasks)\n",
    "    a_taskInds = copy.deepcopy(constraints[0])\n",
    "    alloc = [np.random.choice(a_taskInds[i]+[task_num]) for i in range(0,agent_num)]\n",
    "    return alloc, sys_rewards_tasks(tasks, alloc_to_CS(tasks,alloc), gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_record(record, filename, typ):\n",
    "    with open(filename, 'a') as f:\n",
    "        if typ != '':\n",
    "            json.dump(record, f, default = typ)\n",
    "        else:\n",
    "            json.dump(record, f)\n",
    "        f.write('\\n')\n",
    "        # f.write(os.linesep)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 0\n",
      "task_number:  100 BnBFMS time: 3.7016208171844482 result: 7278 iteration: 301 converge? False\n",
      "task_number:  100 rand result 4715\n",
      "task_number:  100 DSA time: 0.029215097427368164 result: 8079 iteration: 15 messages 1612 converge? True\n",
      "\n",
      "task number:  100 LS_t: 0.01409769058227539 LS_u: 7878 LS_iter: 7 messages 1541 converge? True\n",
      "\n",
      "task_number:  100 disNE time: 0.01145029067993164 result: 8009 iteration: 5 messages 1504 converge? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_num = 100\n",
    "probability = 0.7\n",
    "time_bound = 300\n",
    "max_t_num = 1000\n",
    "capNum = 10\n",
    "max_capNum_task = 10\n",
    "max_capNum_agent = 10\n",
    "\n",
    "a_min_edge = 1\n",
    "min_t_num = 100\n",
    "ex_identifier = 0\n",
    "\n",
    "\n",
    "# compare algorithms\n",
    "for run in range(0, run_num):\n",
    "    print('run:', run)\n",
    "    task_num = min_t_num\n",
    "    while task_num <= max_t_num:\n",
    "        ex_identifier += 1\n",
    "        t_max_edge = 0.04 * task_num\n",
    "        agent_num = 2 * task_num\n",
    "        constraints = gen_constraints(agent_num, task_num, 1, a_min_edge, t_max_edge) #max(M,N)\n",
    "        t_agents = copy.deepcopy(constraints[1])\n",
    "        t_agents.append(list(range(0, agent_num)))\n",
    "\n",
    "        if t_max_edge <= 17:\n",
    "            tasks = gen_tasks_RF(task_num, t_agents)\n",
    "        else: \n",
    "            tasks = gen_tasks_RF2(task_num)\n",
    "\n",
    "\n",
    "        result = {\"ex_identifier\": ex_identifier, \"task_num\": task_num, \"agent_num\": agent_num}\n",
    "\n",
    "        \n",
    "        ##  BnB-FMS\n",
    "        if t_max_edge <= 17:\n",
    "            start = time.time()\n",
    "            new_con = OPD_RF(agent_num, tasks, constraints, gamma=1)\n",
    "            r = FMS_RF(agent_num, tasks, new_con, gamma=1, time_bound=time_bound)\n",
    "            end = time.time()\n",
    "            result['BnBFMS_u'] = r[1]\n",
    "            result['BnBFMS_t'] = end - start\n",
    "            result['BnBFMS_iter'] = r[2]\n",
    "            result['BnBFMS_converge'] = r[4]\n",
    "            print(\"task_number: \", task_num, \"BnBFMS time:\", result['BnBFMS_t'],'result:',result['BnBFMS_u'],\n",
    "                  \"iteration:\", result['BnBFMS_iter'], \"converge?\", result['BnBFMS_converge'])\n",
    "\n",
    "        #  Rand\n",
    "        r = random(agent_num, tasks,constraints, gamma=1)\n",
    "        alloc = r[0]\n",
    "        result['rand'] = r[1]\n",
    "        print(\"task_number: \", task_num, 'rand result',result['rand'])\n",
    "        rand_CS = [[] for i in list(range(0, task_num + 1))]\n",
    "        for i in list(range(0, agent_num)):\n",
    "            rand_CS[alloc[i]].append(i)\n",
    "\n",
    "\n",
    "        ##  DSA\n",
    "        start = time.time()\n",
    "        dsa_u, dsa_iter, dsa_msg_num, if_converge = DSA_RF(constraints, tasks, agent_num, probability, time_bound)\n",
    "        end = time.time()\n",
    "        result['dsa_u'] = dsa_u\n",
    "        result['dsa_t'] = end-start\n",
    "        result['dsa_iter'] = dsa_iter\n",
    "        result['dsa_msg'] = dsa_msg_num\n",
    "        result['DSA_converge'] = if_converge\n",
    "        print(\"task_number: \", task_num, \"DSA time:\", result['dsa_t'],'result:', result['dsa_u'],\n",
    "              \"iteration:\", result['dsa_iter'], \"messages\", result['dsa_msg'], \"converge?\", result['DSA_converge'])\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        ##  DisNE starts from a random solution\n",
    "        rand_disne = copy.deepcopy(rand_CS) \n",
    "        start = time.time()\n",
    "        LS_u, LS_iter, LS_msg_num, if_converge = disNE_RF(constraints, tasks, agent_num, time_bound, rand_disne)\n",
    "        end = time.time()\n",
    "        result['LS_u'] = LS_u\n",
    "        result['LS_t'] = end - start\n",
    "        result['LS_iter'] = LS_iter\n",
    "        result['LS_msg_num'] = LS_msg_num\n",
    "        result['LS_converge'] = if_converge\n",
    "        print(\"task number: \", task_num, \"LS_t:\", result['LS_t'], 'LS_u:', LS_u,\n",
    "                \"LS_iter:\", LS_iter, \"messages\", result['LS_msg_num'], \"converge?\", result['LS_converge'])\n",
    "        print()\n",
    "        \n",
    "        ##  DisNE\n",
    "        start = time.time()\n",
    "        disNE_u, disNE_iter, disNE_msg_num, if_converge = disNE_RF(constraints, tasks, agent_num, time_bound, [])\n",
    "        end = time.time()\n",
    "        result['disNE_u'] = disNE_u\n",
    "        result['disNE_t'] = end-start\n",
    "        result['disNE_iter'] = disNE_iter\n",
    "        result['DisNE_msg'] = disNE_msg_num\n",
    "        result['DisNE_converge'] = if_converge\n",
    "        print(\"task_number: \", task_num, \"disNE time:\", result['disNE_t'],'result:',result['disNE_u'],\n",
    "              \"iteration:\", result['disNE_iter'], \"messages\", result['DisNE_msg'], \"converge?\", result['DisNE_converge'])\n",
    "        print()\n",
    "\n",
    "# #         # append data and result\n",
    "#         files = {'gen_RF_thesis': [result, '']}\n",
    "#         for filename in list(files.keys()):\n",
    "#             append_record(files[filename][0], filename, typ=files[filename][1])\n",
    "\n",
    "#         increase the task_number\n",
    "        task_num += 100\n",
    "    run += 1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
